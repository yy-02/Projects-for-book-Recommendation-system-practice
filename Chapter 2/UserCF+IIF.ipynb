{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users 数据集预览：\n",
      "   UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n",
      "\n",
      "Movies 数据集预览：\n",
      "   MovieID                               Title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                             Genres  \n",
      "0   [Animation, Children's, Comedy]  \n",
      "1  [Adventure, Children's, Fantasy]  \n",
      "2                 [Comedy, Romance]  \n",
      "3                   [Comedy, Drama]  \n",
      "4                          [Comedy]  \n",
      "Ratings 数据集预览：\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# 读取用户数据集，指定列名\n",
    "users = pd.read_csv('users.dat', sep='::', engine='python', header=None,\n",
    "                    names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
    "print(\"Users 数据集预览：\")\n",
    "print(users.head())\n",
    "\n",
    "# 读取电影数据集，指定列名\n",
    "movies = pd.read_csv('movies.dat', sep='::', engine='python', header=None, encoding='latin1',\n",
    "                     names=['MovieID', 'Title', 'Genres'])\n",
    "    \n",
    "# 将 Genres 列中的字符串按 \"|\" 分割，转换成列表\n",
    "movies['Genres'] = movies['Genres'].apply(lambda x: x.split('|'))\n",
    "\n",
    "print(\"\\nMovies 数据集预览：\")\n",
    "print(movies.head())\n",
    "\n",
    "\n",
    "\n",
    "# 读取 ratings 数据集\n",
    "ratings = pd.read_csv('ratings.dat', sep='::', engine='python', header=None,\n",
    "                        names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "print(\"Ratings 数据集预览：\")\n",
    "print(ratings.head())\n",
    "\n",
    "# 对于隐反馈数据，只需要记录 (UserID, MovieID) 对，忽略 Rating 和 Timestamp\n",
    "data = list(zip(ratings['UserID'], ratings['MovieID']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练集大小: 874948, 测试集大小: 125261\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def SplitData(data, M, k, seed):\n",
    "    \"\"\"\n",
    "    将数据集 data 均匀随机划分为 M 份，\n",
    "    k 为当前划分的编号（0 <= k < M），\n",
    "    如果某条数据被随机选中为 k，则划分到测试集，\n",
    "    否则划分到训练集。\n",
    "\n",
    "    参数:\n",
    "    - data: 用户行为数据，格式为 [(user, item), ...]\n",
    "    - M: 划分份数，例如 8\n",
    "    - k: 本次实验选用的测试集编号，0 <= k < M\n",
    "    - seed: 随机种子，用于保证实验可重复\n",
    "\n",
    "    返回:\n",
    "    - train: 训练集列表\n",
    "    - test: 测试集列表\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    train = []\n",
    "    random.seed(seed)\n",
    "    for user, item in data:\n",
    "        # 随机生成 0 到 M-1 之间的一个整数\n",
    "        if random.randint(0, M - 1) == k:\n",
    "            test.append([user, item])\n",
    "        else:\n",
    "            train.append([user, item])\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# 这里选择 M=8，k=0 作为一次实验（可循环不同 k 得到多个结果）\n",
    "M = 8\n",
    "k = 0\n",
    "seed = 42\n",
    "train_data, test_data = SplitData(data, M, k, seed)\n",
    "\n",
    "print(f\"\\n训练集大小: {len(train_data)}, 测试集大小: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户-物品集 & 用户相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户物品集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 构建用户-物品字典（训练集）\n",
    "# ---------------------------\n",
    "def build_user_item_dict(train_data):\n",
    "    \"\"\"\n",
    "    根据训练集，生成 {user: set(items)} 结构\n",
    "    \"\"\"\n",
    "    user_item = defaultdict(set)\n",
    "    for user, item in train_data:\n",
    "        user_item[user].add(item)\n",
    "    return user_item\n",
    "\n",
    "user_item = build_user_item_dict(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 计算用户相似度\n",
    "# ---------------------------\n",
    "def calc_user_similarity(user_item):\n",
    "    \"\"\"\n",
    "    计算用户之间的相似度\n",
    "    使用余弦相似度公式： sim(u,v) = |I(u)∩I(v)| / sqrt(|I(u)|*|I(v)|)\n",
    "    返回一个字典： {u: {v: similarity}}\n",
    "    \"\"\"\n",
    "    # 建立物品到用户的倒排表\n",
    "    item_users = defaultdict(set)\n",
    "    for u, items in user_item.items():\n",
    "        for i in items:         \n",
    "            item_users[i].add(u)\n",
    "\n",
    "    # 共现矩阵：统计两个用户共同交互的物品数\n",
    "    co_occurrence = defaultdict(lambda: defaultdict(int))\n",
    "    user_item_count = {u: len(items) for u, items in user_item.items()}\n",
    "\n",
    "    for i, users in item_users.items():\n",
    "        for u in users:\n",
    "            for v in users:\n",
    "                if u == v:\n",
    "                    continue\n",
    "                co_occurrence[u][v] += 1\n",
    "\n",
    "    # 计算余弦相似度\n",
    "    user_similarity = defaultdict(dict)\n",
    "    for u, related_users in co_occurrence.items():\n",
    "        for v, count in related_users.items():\n",
    "            user_similarity[u][v] = count / math.sqrt(user_item_count[u] * user_item_count[v])\n",
    "    return user_similarity\n",
    "\n",
    "user_similarity = calc_user_similarity(user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU加速版本\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def calc_user_similarity_sparse(user_item):\n",
    "    \"\"\"\n",
    "    计算用户之间的相似度，采用稀疏矩阵加速计算\n",
    "    使用余弦相似度公式：\n",
    "      sim(u, v) = |I(u)∩I(v)| / sqrt(|I(u)| * |I(v)|)\n",
    "      \n",
    "    参数:\n",
    "      user_item: {user: set(item)}\n",
    "      \n",
    "    返回:\n",
    "      user_similarity: {user: {other_user: similarity}}\n",
    "    \"\"\"\n",
    "    # 为用户和物品建立索引映射\n",
    "    users = list(user_item.keys())\n",
    "    user_index = {u: idx for idx, u in enumerate(users)}\n",
    "    \n",
    "    items = set()\n",
    "    for u, it_set in user_item.items():\n",
    "        items.update(it_set)\n",
    "    items = list(items)\n",
    "    item_index = {i: idx for idx, i in enumerate(items)}\n",
    "\n",
    "    # 构建用户-物品稀疏矩阵 (行: 用户，列: 物品)\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for u, it_set in user_item.items():\n",
    "        for i in it_set:\n",
    "            row.append(user_index[u])\n",
    "            col.append(item_index[i])\n",
    "            data.append(1)  # 隐反馈，交互记为1\n",
    "\n",
    "    n_users = len(users)\n",
    "    n_items = len(items)\n",
    "    user_item_mat = sp.csr_matrix((data, (row, col)), shape=(n_users, n_items))\n",
    "    \n",
    "    # 计算共现矩阵：用户与用户之间的共同物品数\n",
    "    co_occurrence_mat = user_item_mat.dot(user_item_mat.T).toarray()  # (n_users, n_users)\n",
    "    \n",
    "    # 每个用户的交互数（即行和）\n",
    "    user_counts = np.array(user_item_mat.sum(axis=1)).flatten()\n",
    "    \n",
    "    # 构建归一化矩阵：sqrt(|I(u)|*|I(v)|)\n",
    "    norm_matrix = np.outer(user_counts, user_counts)\n",
    "    norm_matrix = np.sqrt(norm_matrix)\n",
    "    \n",
    "    # 计算余弦相似度：逐元素除法，注意避免除以0\n",
    "    similarity_mat = np.divide(co_occurrence_mat, norm_matrix, where=(norm_matrix != 0))\n",
    "    \n",
    "    # 将相似度矩阵转换为字典格式，仅保留相似度大于0且 u != v 的部分\n",
    "    user_similarity = {}\n",
    "    for i, u in enumerate(users):\n",
    "        user_similarity[u] = {}\n",
    "        for j, v in enumerate(users):\n",
    "            if i != j and similarity_mat[i, j] > 0:\n",
    "                user_similarity[u][v] = similarity_mat[i, j]\n",
    "    return user_similarity\n",
    "\n",
    "# 示例用法，假设 user_item 已经由训练数据构建：\n",
    "# user_item = build_user_item_dict(train_data)\n",
    "user_similarity = calc_user_similarity_sparse(user_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐UserCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 推荐函数（UserCF）\n",
    "# ---------------------------\n",
    "def recommend(user, user_item, user_similarity, K=20, N=10):\n",
    "    \"\"\"\n",
    "    为目标用户 user 推荐 N 个物品\n",
    "    K: 考虑相似度最高的 K 个邻居\n",
    "    \"\"\"\n",
    "    interacted_items = user_item.get(user, set())\n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    # 若用户在训练集中没有行为，直接返回空推荐\n",
    "    if user not in user_similarity:\n",
    "        return []\n",
    "    \n",
    "    # 选取相似度最高的 K 个邻居\n",
    "    neighbors = sorted(user_similarity[user].items(), key=lambda x: x[1], reverse=True)[:K]\n",
    "    \n",
    "    for neighbor, sim in neighbors: # sim表示相似度\n",
    "        for item in user_item.get(neighbor, set()): #这里遍历了邻居用户 neighbor 交互过的所有物品\n",
    "            if item in interacted_items:  #跳过当前用户已经交互的物品，即协同过滤中的过滤\n",
    "                continue\n",
    "            scores[item] += sim  # 可根据需要加入加权策略\n",
    "    \n",
    "    ranked_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:N]\n",
    "    return [item for item, score in ranked_items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 评测函数\n",
    "# ---------------------------\n",
    "def evaluate(user_item, test_data, user_similarity, K=20, N=10):\n",
    "    \"\"\"\n",
    "    在测试集上评测推荐效果，计算 Precision、Recall、Coverage 和 Popularity\n",
    "    \"\"\"\n",
    "    # 构建测试集的用户-物品字典\n",
    "    test_user_item = defaultdict(set)\n",
    "    for user, item in test_data:\n",
    "        test_user_item[user].add(item)\n",
    "    \n",
    "    # 计算所有物品的流行度（出现次数），用于流行度评估\n",
    "    item_popularity = defaultdict(int)\n",
    "    for items in user_item.values():\n",
    "        for item in items:\n",
    "            item_popularity[item] += 1\n",
    "    all_items = set(item_popularity.keys())\n",
    "    \n",
    "    hit = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    recommended_items_set = set()\n",
    "    total_test_items = 0\n",
    "\n",
    "    # 用于计算推荐列表的平均流行度\n",
    "    total_popularity = 0\n",
    "    total_rec = 0\n",
    "    \n",
    "    users = set(list(user_item.keys()) + list(test_user_item.keys()))\n",
    "    \n",
    "    for user in users:\n",
    "        rec_items = recommend(user, user_item, user_similarity, K=K, N=N)\n",
    "        true_items = test_user_item.get(user, set()) #从测试集中获取当前用户的真实交互物品集合\n",
    "        hit += len(set(rec_items) & true_items) #计算当前用户推荐列表中有多少物品出现在真实交互集合中，即交集的大小\n",
    "        \n",
    "        total_precision += N #precision 分母\n",
    "        total_recall += len(true_items) #recall 分母\n",
    "        \n",
    "        recommended_items_set.update(rec_items)\n",
    "        \n",
    "        total_test_items += len(true_items) #统计所有用户在测试集中真实交互物品的总数量，计算召回率\n",
    "        \n",
    "        #计算流行度\n",
    "        for item in rec_items:\n",
    "            total_popularity += math.log(1 + item_popularity.get(item, 0))  #取对数平滑数据防止极值\n",
    "            total_rec += 1\n",
    "\n",
    "    precision = hit / (total_precision + 1e-10)\n",
    "    recall = hit / (total_recall + 1e-10)\n",
    "    coverage = len(recommended_items_set) / len(all_items)\n",
    "    popularity = total_popularity / (total_rec + 1e-10)\n",
    "    \n",
    "    return precision, recall, coverage, popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验运行和结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "评测结果：\n",
      "Precision: 0.2510\n",
      "Recall:    0.1210\n",
      "Coverage:  0.2047\n",
      "Popularity:7.2850\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 执行一次实验并输出评测结果\n",
    "# ---------------------------\n",
    "K = 80   # 邻居数\n",
    "N = 10   # 推荐列表长度\n",
    "precision, recall, coverage, popularity = evaluate(user_item, test_data, user_similarity, K=K, N=N)\n",
    "print(f\"\\n评测结果：\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"Coverage:  {coverage:.4f}\")\n",
    "print(f\"Popularity:{popularity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
